"""
Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø³Ù„ÙˆÙƒ | Agent Principal de Collecte | Main Behavior Collector
ÙŠØ¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ù† Ù…Ø±Ø§Ù‚Ø¨ÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ÙˆØ§Ù„Ø´Ø¨ÙƒØ© ÙˆØ§Ù„Ù…Ù„ÙØ§Øª
Collecte tous les Ã©vÃ©nements des moniteurs de processus, rÃ©seau et fichiers
"""

import os
import sys
import json
import time
import yaml
import threading
import argparse
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from datetime import datetime
from pathlib import Path
import logging
from collections import deque

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† | Importer les moniteurs
from .process_monitor import ProcessMonitor, ProcessEvent
from .network_monitor import NetworkMonitor, NetworkEvent
from .file_monitor import FileMonitor, SimpleFileMonitor, FileEvent

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ | Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class UnifiedEvent:
    """
    Ø­Ø¯Ø« Ù…ÙˆØ­Ø¯ ÙŠØ¬Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø«
    Ã‰vÃ©nement unifiÃ© regroupant tous les types
    """
    timestamp: float
    timestamp_iso: str
    source: str  # process, network, file
    event_type: str
    data: Dict[str, Any]
    label: str = "benign"  # benign, malicious
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    def to_json(self) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=False)


class BehaviorCollector:
    """
    Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ø¬Ù…Ø¹ Ø§Ù„Ø³Ù„ÙˆÙƒ | Agent Principal de Collecte
    ÙŠØ¬Ù…Ø¹ ÙˆÙŠÙˆØ­Ø¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† Ø§Ù„Ù…Ø®ØªÙ„ÙÙŠÙ†
    Collecte et unifie tous les Ã©vÃ©nements des diffÃ©rents moniteurs
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ | Initialisation de l'agent
        
        Args:
            config_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ØªÙƒÙˆÙŠÙ† | Chemin du fichier de configuration
        """
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙƒÙˆÙŠÙ† | Charger la configuration
        self.config = self._load_config(config_path)
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…ÙˆØ­Ø¯Ø© | Liste des Ã©vÃ©nements unifiÃ©s
        self._events: deque = deque(maxlen=self.config.get('max_events_buffer', 100000))
        self._lock = threading.Lock()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Configurer les chemins de donnÃ©es
        self.data_dir = Path(self.config.get('data_dir', './data'))
        self.raw_dir = self.data_dir / 'raw'
        self.raw_dir.mkdir(parents=True, exist_ok=True)
        
        # Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© | RÃ©pertoire de surveillance
        self.watch_dir = self.data_dir / 'test_sandbox'
        self.watch_dir.mkdir(parents=True, exist_ok=True)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† | CrÃ©er les moniteurs
        self._init_monitors()
        
        # Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ | Fichier de sortie
        self._output_file = None
        self._output_format = self.config.get('output_format', 'jsonl')
        
        # Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© | Label actuel
        self._current_label = "benign"
        
        # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Statistiques
        self._stats = {
            'process_events': 0,
            'network_events': 0,
            'file_events': 0,
            'total_events': 0,
            'start_time': None
        }
        
        logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© ÙˆÙƒÙŠÙ„ Ø¬Ù…Ø¹ Ø§Ù„Ø³Ù„ÙˆÙƒ | Agent de collecte initialisÃ©")
    
    def _load_config(self, config_path: Optional[str]) -> Dict:
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ù…Ù† Ù…Ù„Ù | Charger la configuration
        """
        default_config = {
            'collection_interval': 0.5,
            'feature_window': 10,
            'max_events_buffer': 100000,
            'data_dir': './data',
            'output_format': 'jsonl',
            'process_monitor': {
                'enabled': True,
                'excluded_processes': ['System', 'System Idle Process', 'Registry']
            },
            'network_monitor': {
                'enabled': True,
                'excluded_ports': []
            },
            'file_monitor': {
                'enabled': True,
                'watch_directories': ['./data/test_sandbox'],
                'watch_extensions': ['.txt', '.doc', '.pdf', '.json', '.csv', '.py']
            }
        }
        
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    loaded_config = yaml.safe_load(f)
                    if loaded_config:
                        # Ø¯Ù…Ø¬ Ø§Ù„ØªÙƒÙˆÙŠÙ†Ø§Øª | Fusionner les configurations
                        self._deep_merge(default_config, loaded_config)
                logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ù…Ù† | Configuration chargÃ©e de: {config_path}")
            except Exception as e:
                logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙƒÙˆÙŠÙ† | Erreur de chargement: {e}")
        
        return default_config
    
    def _deep_merge(self, base: Dict, update: Dict):
        """
        Ø¯Ù…Ø¬ Ø¹Ù…ÙŠÙ‚ Ù„Ù„Ù‚ÙˆØ§Ù…ÙŠØ³ | Fusion profonde des dictionnaires
        """
        for key, value in update.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._deep_merge(base[key], value)
            else:
                base[key] = value
    
    def _init_monitors(self):
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† | CrÃ©er les moniteurs
        """
        interval = self.config.get('collection_interval', 0.5)
        
        # Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª | Moniteur de processus
        proc_config = self.config.get('process_monitor', {})
        if proc_config.get('enabled', True):
            self.process_monitor = ProcessMonitor(
                interval=interval,
                excluded_processes=proc_config.get('excluded_processes', []),
                callback=self._on_process_event
            )
        else:
            self.process_monitor = None
        
        # Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø´Ø¨ÙƒØ© | Moniteur rÃ©seau
        net_config = self.config.get('network_monitor', {})
        if net_config.get('enabled', True):
            self.network_monitor = NetworkMonitor(
                interval=interval,
                excluded_ports=net_config.get('excluded_ports', []),
                callback=self._on_network_event
            )
        else:
            self.network_monitor = None
        
        # Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª | Moniteur de fichiers
        file_config = self.config.get('file_monitor', {})
        if file_config.get('enabled', True):
            watch_dirs = file_config.get('watch_directories', [str(self.watch_dir)])
            # ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª | S'assurer que les rÃ©pertoires existent
            for d in watch_dirs:
                Path(d).mkdir(parents=True, exist_ok=True)
            
            try:
                self.file_monitor = FileMonitor(
                    watch_directories=watch_dirs,
                    watch_extensions=file_config.get('watch_extensions', []),
                    callback=self._on_file_event,
                    recursive=True
                )
            except ImportError:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø¨Ø³ÙŠØ· ÙƒØ¨Ø¯ÙŠÙ„
                logger.warning("Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨Ø³ÙŠØ· | Utilisation du moniteur simple")
                self.file_monitor = SimpleFileMonitor(
                    watch_directories=watch_dirs,
                    interval=interval,
                    callback=self._on_file_event
                )
        else:
            self.file_monitor = None
    
    def _create_unified_event(self, source: str, event_type: str, data: Dict) -> UnifiedEvent:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø­Ø¯Ø« Ù…ÙˆØ­Ø¯ | CrÃ©er un Ã©vÃ©nement unifiÃ©
        """
        now = datetime.now()
        return UnifiedEvent(
            timestamp=time.time() * 1000,
            timestamp_iso=now.isoformat(),
            source=source,
            event_type=event_type,
            data=data,
            label=self._current_label
        )
    
    def _add_event(self, event: UnifiedEvent):
        """
        Ø¥Ø¶Ø§ÙØ© Ø­Ø¯Ø« Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© | Ajouter un Ã©vÃ©nement Ã  la liste
        """
        with self._lock:
            self._events.append(event)
            self._stats['total_events'] += 1
        
        # ÙƒØªØ§Ø¨Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØªÙˆØ­Ø§Ù‹ | Ã‰crire dans le fichier si ouvert
        if self._output_file:
            try:
                self._output_file.write(event.to_json() + '\n')
                self._output_file.flush()
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨Ø© | Erreur d'Ã©criture: {e}")
    
    def _on_process_event(self, event: ProcessEvent):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø¯Ø« Ø§Ù„Ø¹Ù…Ù„ÙŠØ© | Traiter un Ã©vÃ©nement processus
        """
        unified = self._create_unified_event(
            source="process",
            event_type=event.event_type,
            data=event.to_dict()
        )
        self._add_event(unified)
        self._stats['process_events'] += 1
    
    def _on_network_event(self, event: NetworkEvent):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø¯Ø« Ø§Ù„Ø´Ø¨ÙƒØ© | Traiter un Ã©vÃ©nement rÃ©seau
        """
        unified = self._create_unified_event(
            source="network",
            event_type=event.event_type,
            data=event.to_dict()
        )
        self._add_event(unified)
        self._stats['network_events'] += 1
    
    def _on_file_event(self, event: FileEvent):
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø­Ø¯Ø« Ø§Ù„Ù…Ù„Ù | Traiter un Ã©vÃ©nement fichier
        """
        unified = self._create_unified_event(
            source="file",
            event_type=event.event_type,
            data=event.to_dict()
        )
        self._add_event(unified)
        self._stats['file_events'] += 1
    
    def set_label(self, label: str):
        """
        ØªØ¹ÙŠÙŠÙ† Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„Ø£Ø­Ø¯Ø§Ø« | DÃ©finir le label actuel
        
        Args:
            label: Ø§Ù„ØªØ³Ù…ÙŠØ© (benign/malicious) | Label
        """
        self._current_label = label
        logger.info(f"ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„ØªØ³Ù…ÙŠØ© | Label dÃ©fini: {label}")
    
    def start(self, output_file: Optional[str] = None):
        """
        Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ù…Ø¹ | DÃ©marrer la collecte
        
        Args:
            output_file: Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) | Fichier de sortie (optionnel)
        """
        logger.info("=" * 60)
        logger.info("Ø¨Ø¯Ø¡ ÙˆÙƒÙŠÙ„ Ø¬Ù…Ø¹ Ø§Ù„Ø³Ù„ÙˆÙƒ | DÃ©marrage de l'agent de collecte")
        logger.info("=" * 60)
        
        self._stats['start_time'] = time.time()
        
        # ÙØªØ­ Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ | Ouvrir le fichier de sortie
        if output_file:
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            self._output_file = open(output_path, 'a', encoding='utf-8')
            logger.info(f"Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø¥Ù„Ù‰ | Ã‰criture vers: {output_file}")
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† | DÃ©marrer les moniteurs
        if self.process_monitor:
            self.process_monitor.start()
            logger.info("âœ… Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª | Moniteur processus")
        
        if self.network_monitor:
            self.network_monitor.start()
            logger.info("âœ… Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø´Ø¨ÙƒØ© | Moniteur rÃ©seau")
        
        if self.file_monitor:
            self.file_monitor.start()
            logger.info("âœ… Ù…Ø±Ø§Ù‚Ø¨ Ø§Ù„Ù…Ù„ÙØ§Øª | Moniteur fichiers")
        
        logger.info("Ø§Ù„ÙˆÙƒÙŠÙ„ ÙŠØ¹Ù…Ù„ Ø§Ù„Ø¢Ù† | Agent en cours d'exÃ©cution")
    
    def stop(self):
        """
        Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¬Ù…Ø¹ | ArrÃªter la collecte
        """
        logger.info("Ø¥ÙŠÙ‚Ø§Ù ÙˆÙƒÙŠÙ„ Ø¬Ù…Ø¹ Ø§Ù„Ø³Ù„ÙˆÙƒ | ArrÃªt de l'agent de collecte")
        
        # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨ÙŠÙ† | ArrÃªter les moniteurs
        if self.process_monitor:
            self.process_monitor.stop()
        
        if self.network_monitor:
            self.network_monitor.stop()
        
        if self.file_monitor:
            self.file_monitor.stop()
        
        # Ø¥ØºÙ„Ø§Ù‚ Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ | Fermer le fichier de sortie
        if self._output_file:
            self._output_file.close()
            self._output_file = None
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Afficher les statistiques
        self._print_stats()
    
    def _print_stats(self):
        """
        Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Afficher les statistiques
        """
        duration = time.time() - self._stats['start_time'] if self._stats['start_time'] else 0
        
        print("\n" + "=" * 60)
        print("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù…Ø¹ | Statistiques de Collecte")
        print("=" * 60)
        print(f"â±ï¸  Ø§Ù„Ù…Ø¯Ø© | DurÃ©e: {duration:.1f} Ø«Ø§Ù†ÙŠØ© | secondes")
        print(f"ğŸ“¦ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« | Total Ã©vÃ©nements: {self._stats['total_events']}")
        print(f"   - Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª | Processus: {self._stats['process_events']}")
        print(f"   - Ø§Ù„Ø´Ø¨ÙƒØ© | RÃ©seau: {self._stats['network_events']}")
        print(f"   - Ø§Ù„Ù…Ù„ÙØ§Øª | Fichiers: {self._stats['file_events']}")
        if duration > 0:
            rate = self._stats['total_events'] / duration
            print(f"ğŸ“ˆ Ø§Ù„Ù…Ø¹Ø¯Ù„ | Taux: {rate:.1f} Ø­Ø¯Ø«/Ø«Ø§Ù†ÙŠØ© | Ã©vÃ©nements/s")
        print("=" * 60)
    
    def get_events(self, clear: bool = False) -> List[UnifiedEvent]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ø¬Ù…Ø¹Ø© | Obtenir les Ã©vÃ©nements collectÃ©s
        """
        with self._lock:
            events = list(self._events)
            if clear:
                self._events.clear()
        return events
    
    def get_events_as_dicts(self, clear: bool = False) -> List[Dict]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙƒÙ‚ÙˆØ§Ù…ÙŠØ³ | Obtenir les Ã©vÃ©nements comme dicts
        """
        return [e.to_dict() for e in self.get_events(clear)]
    
    def get_stats(self) -> Dict:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Obtenir les statistiques
        """
        return self._stats.copy()
    
    def save_to_file(self, filepath: str, format: str = 'jsonl'):
        """
        Ø­ÙØ¸ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø¥Ù„Ù‰ Ù…Ù„Ù | Sauvegarder les Ã©vÃ©nements dans un fichier
        
        Args:
            filepath: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù | Chemin du fichier
            format: Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ (jsonl/csv) | Format
        """
        events = self.get_events()
        filepath = Path(filepath)
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        if format == 'jsonl':
            with open(filepath, 'w', encoding='utf-8') as f:
                for event in events:
                    f.write(event.to_json() + '\n')
        
        elif format == 'csv':
            import csv
            if events:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ | Extraire toutes les clÃ©s
                all_keys = set()
                for event in events:
                    all_keys.update(event.to_dict().keys())
                    all_keys.update(event.data.keys())
                
                with open(filepath, 'w', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=sorted(all_keys))
                    writer.writeheader()
                    for event in events:
                        row = event.to_dict()
                        row.update(event.data)
                        writer.writerow(row)
        
        logger.info(f"ØªÙ… Ø­ÙØ¸ {len(events)} Ø­Ø¯Ø« Ø¥Ù„Ù‰ | {len(events)} Ã©vÃ©nements sauvegardÃ©s: {filepath}")


def main():
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© | Fonction principale
    """
    parser = argparse.ArgumentParser(
        description="ÙˆÙƒÙŠÙ„ Ø¬Ù…Ø¹ Ø§Ù„Ø³Ù„ÙˆÙƒ | Agent de Collecte Comportementale"
    )
    parser.add_argument(
        '--config', '-c',
        type=str,
        default='config/config.yaml',
        help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„ØªÙƒÙˆÙŠÙ† | Chemin du fichier de configuration'
    )
    parser.add_argument(
        '--output', '-o',
        type=str,
        default=None,
        help='Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ | Fichier de sortie'
    )
    parser.add_argument(
        '--duration', '-d',
        type=int,
        default=60,
        help='Ù…Ø¯Ø© Ø§Ù„Ø¬Ù…Ø¹ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ | DurÃ©e de collecte en secondes'
    )
    parser.add_argument(
        '--label', '-l',
        type=str,
        default='benign',
        choices=['benign', 'malicious'],
        help='ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø­Ø¯Ø§Ø« | Label des Ã©vÃ©nements'
    )
    parser.add_argument(
        '--test',
        action='store_true',
        help='ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± | Mode test'
    )
    
    args = parser.parse_args()
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆÙƒÙŠÙ„ | CrÃ©er l'agent
    collector = BehaviorCollector(config_path=args.config)
    collector.set_label(args.label)
    
    # ØªØ­Ø¯ÙŠØ¯ Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ | DÃ©finir le fichier de sortie
    if args.output:
        output_file = args.output
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"data/raw/events_{args.label}_{timestamp}.jsonl"
    
    try:
        # Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ù…Ø¹ | DÃ©marrer la collecte
        collector.start(output_file=output_file)
        
        if args.test:
            print("\nğŸ§ª ÙˆØ¶Ø¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± | Mode Test (5 Ø«ÙˆØ§Ù†)")
            time.sleep(5)
        else:
            print(f"\nâ³ Ø§Ù„Ø¬Ù…Ø¹ Ù„Ù…Ø¯Ø© {args.duration} Ø«Ø§Ù†ÙŠØ©... | Collecte pendant {args.duration} secondes...")
            print("Ø§Ø¶ØºØ· Ctrl+C Ù„Ù„Ø¥ÙŠÙ‚Ø§Ù | Appuyez sur Ctrl+C pour arrÃªter")
            time.sleep(args.duration)
    
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ØªÙˆÙ‚Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… | ArrÃªt par l'utilisateur")
    
    finally:
        collector.stop()


if __name__ == "__main__":
    main()
