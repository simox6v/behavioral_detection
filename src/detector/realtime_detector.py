"""
Ø§Ù„ÙƒØ´Ù Ø§Ù„ÙÙˆØ±ÙŠ | DÃ©tection en Temps RÃ©el | Real-time Detection
ÙƒØ´Ù Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
DÃ©tection du comportement suspect en temps rÃ©el
"""

import os
import sys
import time
import json
import threading
import tracemalloc
from typing import Dict, List, Optional, Any, Callable
from pathlib import Path
from datetime import datetime
from collections import deque
from dataclasses import dataclass
import logging
import joblib
import numpy as np

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„ÙˆØ­Ø¯Ø§Øª | Importer les modules
try:
    from ..collector.behavior_collector import BehaviorCollector
    from ..features.feature_engineering import FeatureExtractor
except ImportError:
    BehaviorCollector = None
    FeatureExtractor = None

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ | Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class DetectionResult:
    """
    Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ´Ù | RÃ©sultat de DÃ©tection
    """
    timestamp: float
    timestamp_iso: str
    prediction: str  # benign, malicious
    confidence: float  # 0.0 - 1.0
    model_name: str
    features: Dict[str, float]
    alert_level: str  # normal, warning, danger
    latency_ms: float
    memory_mb: float
    
    def to_dict(self) -> Dict:
        return {
            'timestamp': self.timestamp,
            'timestamp_iso': self.timestamp_iso,
            'prediction': self.prediction,
            'confidence': self.confidence,
            'model_name': self.model_name,
            'features': self.features,
            'alert_level': self.alert_level,
            'latency_ms': self.latency_ms,
            'memory_mb': self.memory_mb
        }
    
    def to_json(self) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=False)


class RealtimeDetector:
    """
    Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„ÙÙˆØ±ÙŠ | DÃ©tecteur en Temps RÃ©el
    ÙŠÙƒØ´Ù Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
    DÃ©tecte le comportement suspect en temps rÃ©el
    
    Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª | Exigences:
    - Ø²Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© < 2 Ø«Ø§Ù†ÙŠØ© | Latence < 2 secondes
    - Ø§Ø³ØªØ®Ø¯Ø§Ù… RAM < 80 Mo | RAM < 80 Mo
    """
    
    def __init__(
        self,
        model_path: Optional[str] = None,
        scaler_path: Optional[str] = None,
        model_name: str = 'isolation_forest',
        config_path: Optional[str] = None,
        alert_threshold: float = 0.7,
        window_size: float = 10.0,
        max_latency: float = 2.0,
        max_memory_mb: float = 80.0
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ø´Ù | Initialisation du dÃ©tecteur
        
        Args:
            model_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Chemin du modÃ¨le
            scaler_path: Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ | Chemin du scaler
            model_name: Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Nom du modÃ¨le
            config_path: Ù…Ø³Ø§Ø± Ø§Ù„ØªÙƒÙˆÙŠÙ† | Chemin de configuration
            alert_threshold: Ø¹ØªØ¨Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ | Seuil d'alerte
            window_size: Ø­Ø¬Ù… Ø§Ù„Ù†Ø§ÙØ°Ø© | Taille de la fenÃªtre
            max_latency: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØªØ£Ø®ÙŠØ± | Latence maximale
            max_memory_mb: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø°Ø§ÙƒØ±Ø© | RAM maximale
        """
        self.model_name = model_name
        self.alert_threshold = alert_threshold
        self.window_size = window_size
        self.max_latency = max_latency
        self.max_memory_mb = max_memory_mb
        
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Charger le modÃ¨le
        self.model = None
        self.scaler = None
        self.is_anomaly_detector = model_name in ['isolation_forest', 'one_class_svm', 'lof']
        
        if model_path and os.path.exists(model_path):
            self.model = joblib.load(model_path)
            logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | ModÃ¨le chargÃ©: {model_path}")
        
        if scaler_path and os.path.exists(scaler_path):
            self.scaler = joblib.load(scaler_path)
            logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ | Scaler chargÃ©: {scaler_path}")
        
        # Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª | Extracteur de features
        self.feature_extractor = FeatureExtractor(window_size=window_size) if FeatureExtractor else None
        
        # Ø§Ù„Ù…Ø®Ø²Ù† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„Ù„Ø£Ø­Ø¯Ø§Ø« | Buffer d'Ã©vÃ©nements
        self._event_buffer: deque = deque(maxlen=10000)
        
        # Ø³Ø¬Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ | Historique des rÃ©sultats
        self._detection_history: deque = deque(maxlen=1000)
        
        # Ø­Ø§Ù„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ | Ã‰tat d'exÃ©cution
        self._running = False
        self._detection_thread: Optional[threading.Thread] = None
        self._lock = threading.Lock()
        
        # Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ | Callback d'alerte
        self._alert_callback: Optional[Callable[[DetectionResult], None]] = None
        
        # Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Statistiques
        self._stats = {
            'total_detections': 0,
            'malicious_count': 0,
            'benign_count': 0,
            'avg_latency_ms': 0.0,
            'max_latency_ms': 0.0,
            'current_memory_mb': 0.0
        }
        
        logger.info(f"ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„ÙÙˆØ±ÙŠ | DÃ©tecteur initialisÃ©")
        logger.info(f"   Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | ModÃ¨le: {model_name}")
        logger.info(f"   Ø§Ù„Ù†Ø§ÙØ°Ø© | FenÃªtre: {window_size}s")
        logger.info(f"   Ø§Ù„ØªØ£Ø®ÙŠØ± Ø§Ù„Ø£Ù‚ØµÙ‰ | Latence max: {max_latency}s")
        logger.info(f"   Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù‚ØµÙˆÙ‰ | RAM max: {max_memory_mb} MB")
    
    def set_alert_callback(self, callback: Callable[[DetectionResult], None]):
        """
        ØªØ¹ÙŠÙŠÙ† Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ | DÃ©finir le callback d'alerte
        """
        self._alert_callback = callback
    
    def add_event(self, event: Dict):
        """
        Ø¥Ø¶Ø§ÙØ© Ø­Ø¯Ø« Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© | Ajouter un Ã©vÃ©nement Ã  traiter
        """
        with self._lock:
            self._event_buffer.append(event)
        
        if self.feature_extractor:
            self.feature_extractor.add_event(event)
    
    def predict(self, features: Dict[str, float]) -> DetectionResult:
        """
        Ø§Ù„ØªÙ†Ø¨Ø¤ Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª | PrÃ©dire Ã  partir des features
        
        Args:
            features: Ø§Ù„Ù…ÙŠØ²Ø§Øª | Features
            
        Returns:
            Ù†ØªÙŠØ¬Ø© Ø§Ù„ÙƒØ´Ù | RÃ©sultat de dÃ©tection
        """
        start_time = time.time()
        tracemalloc.start()
        
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ© | Convertir en array
            feature_names = list(features.keys())
            feature_values = np.array([[features.get(name, 0) for name in feature_names]])
            
            # Ø§Ù„ØªØ·Ø¨ÙŠØ¹ | Normaliser
            if self.scaler is not None:
                try:
                    feature_values = self.scaler.transform(feature_values)
                except:
                    pass
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤ | PrÃ©dire
            prediction = 'benign'
            confidence = 0.5
            
            if self.model is not None:
                if self.is_anomaly_detector:
                    raw_pred = self.model.predict(feature_values)[0]
                    # -1 = anomaly, 1 = normal
                    prediction = 'malicious' if raw_pred == -1 else 'benign'
                    
                    # Ø§Ù„Ø«Ù‚Ø© Ù…Ù† Ø¯Ø±Ø¬Ø© Ø§Ù„Ø´Ø°ÙˆØ° | Confiance depuis le score
                    if hasattr(self.model, 'score_samples'):
                        score = -self.model.score_samples(feature_values)[0]
                        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¯Ø±Ø¬Ø© | Normaliser le score
                        confidence = min(max(score, 0), 1)
                    elif hasattr(self.model, 'decision_function'):
                        score = -self.model.decision_function(feature_values)[0]
                        confidence = 1 / (1 + np.exp(-score))  # sigmoid
                    else:
                        confidence = 0.8 if prediction == 'malicious' else 0.2
                else:
                    prediction = 'malicious' if self.model.predict(feature_values)[0] == 1 else 'benign'
                    if hasattr(self.model, 'predict_proba'):
                        confidence = float(self.model.predict_proba(feature_values)[0][1])
                    else:
                        confidence = 0.9 if prediction == 'malicious' else 0.1
            
            # ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ | DÃ©terminer le niveau d'alerte
            if prediction == 'malicious' and confidence >= self.alert_threshold:
                alert_level = 'danger'
            elif prediction == 'malicious' or confidence >= 0.5:
                alert_level = 'warning'
            else:
                alert_level = 'normal'
            
            # Ù‚ÙŠØ§Ø³ Ø§Ù„Ø£Ø¯Ø§Ø¡ | Mesurer les performances
            latency = (time.time() - start_time) * 1000  # ms
            current, peak = tracemalloc.get_traced_memory()
            memory_mb = peak / 1024 / 1024
            tracemalloc.stop()
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ØªÙŠØ¬Ø© | CrÃ©er le rÃ©sultat
            result = DetectionResult(
                timestamp=time.time() * 1000,
                timestamp_iso=datetime.now().isoformat(),
                prediction=prediction,
                confidence=float(confidence),
                model_name=self.model_name,
                features=features,
                alert_level=alert_level,
                latency_ms=latency,
                memory_mb=memory_mb
            )
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Mettre Ã  jour les stats
            self._update_stats(result)
            
            # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„ | Sauvegarder dans l'historique
            with self._lock:
                self._detection_history.append(result)
            
            # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ | Appeler le callback
            if alert_level != 'normal' and self._alert_callback:
                self._alert_callback(result)
            
            return result
            
        except Exception as e:
            logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ | Erreur de prÃ©diction: {e}")
            tracemalloc.stop()
            
            return DetectionResult(
                timestamp=time.time() * 1000,
                timestamp_iso=datetime.now().isoformat(),
                prediction='error',
                confidence=0.0,
                model_name=self.model_name,
                features=features,
                alert_level='warning',
                latency_ms=(time.time() - start_time) * 1000,
                memory_mb=0.0
            )
    
    def detect_current(self) -> DetectionResult:
        """
        Ø§Ù„ÙƒØ´Ù Ù…Ù† Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø­Ø§Ù„ÙŠØ© | DÃ©tecter depuis les Ã©vÃ©nements actuels
        """
        if self.feature_extractor:
            features = self.feature_extractor.get_current_features()
        else:
            features = {}
        
        return self.predict(features)
    
    def _update_stats(self, result: DetectionResult):
        """
        ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Mettre Ã  jour les statistiques
        """
        self._stats['total_detections'] += 1
        
        if result.prediction == 'malicious':
            self._stats['malicious_count'] += 1
        else:
            self._stats['benign_count'] += 1
        
        # Ø§Ù„Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ù„Ù„ØªØ£Ø®ÙŠØ± | Moyenne mobile de la latence
        n = self._stats['total_detections']
        old_avg = self._stats['avg_latency_ms']
        self._stats['avg_latency_ms'] = old_avg + (result.latency_ms - old_avg) / n
        
        self._stats['max_latency_ms'] = max(self._stats['max_latency_ms'], result.latency_ms)
        self._stats['current_memory_mb'] = result.memory_mb
    
    def _detection_loop(self, interval: float = 1.0):
        """
        Ø­Ù„Ù‚Ø© Ø§Ù„ÙƒØ´Ù Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© | Boucle de dÃ©tection principale
        """
        logger.info("Ø¨Ø¯Ø¡ Ø­Ù„Ù‚Ø© Ø§Ù„ÙƒØ´Ù | DÃ©marrage de la boucle de dÃ©tection")
        
        while self._running:
            try:
                result = self.detect_current()
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ | VÃ©rifier les performances
                if result.latency_ms > self.max_latency * 1000:
                    logger.warning(f"âš ï¸ ØªØ£Ø®ÙŠØ± Ø¹Ø§Ù„ÙŠ | Latence Ã©levÃ©e: {result.latency_ms:.1f}ms")
                
                if result.memory_mb > self.max_memory_mb:
                    logger.warning(f"âš ï¸ Ø°Ø§ÙƒØ±Ø© Ø¹Ø§Ù„ÙŠØ© | RAM Ã©levÃ©e: {result.memory_mb:.1f}MB")
                
                time.sleep(interval)
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ø­Ù„Ù‚Ø© Ø§Ù„ÙƒØ´Ù | Erreur dans la boucle: {e}")
                time.sleep(1)
        
        logger.info("ØªÙˆÙ‚Ù Ø­Ù„Ù‚Ø© Ø§Ù„ÙƒØ´Ù | Boucle de dÃ©tection arrÃªtÃ©e")
    
    def start(self, interval: float = 1.0):
        """
        Ø¨Ø¯Ø¡ Ø§Ù„ÙƒØ´Ù Ø§Ù„ÙÙˆØ±ÙŠ | DÃ©marrer la dÃ©tection en temps rÃ©el
        """
        if self._running:
            logger.warning("Ø§Ù„ÙƒØ§Ø´Ù ÙŠØ¹Ù…Ù„ Ø¨Ø§Ù„ÙØ¹Ù„ | DÃ©tecteur dÃ©jÃ  en cours")
            return
        
        self._running = True
        self._detection_thread = threading.Thread(
            target=self._detection_loop,
            args=(interval,),
            daemon=True
        )
        self._detection_thread.start()
        
        logger.info("âœ… ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„ÙÙˆØ±ÙŠ | DÃ©tecteur dÃ©marrÃ©")
    
    def stop(self):
        """
        Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ´Ù | ArrÃªter la dÃ©tection
        """
        self._running = False
        if self._detection_thread:
            self._detection_thread.join(timeout=2)
        
        logger.info("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ø´Ù | DÃ©tecteur arrÃªtÃ©")
    
    def get_history(self, count: int = 100) -> List[DetectionResult]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø³Ø¬Ù„ Ø§Ù„ÙƒØ´Ù | Obtenir l'historique de dÃ©tection
        """
        with self._lock:
            return list(self._detection_history)[-count:]
    
    def get_stats(self) -> Dict:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª | Obtenir les statistiques
        """
        return self._stats.copy()
    
    def get_status(self) -> Dict:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„ÙƒØ§Ø´Ù | Obtenir l'Ã©tat du dÃ©tecteur
        """
        return {
            'running': self._running,
            'model_name': self.model_name,
            'model_loaded': self.model is not None,
            'scaler_loaded': self.scaler is not None,
            'window_size': self.window_size,
            'alert_threshold': self.alert_threshold,
            'events_in_buffer': len(self._event_buffer),
            'detections_count': len(self._detection_history),
            **self._stats
        }
    
    def print_status(self):
        """
        Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø­Ø§Ù„Ø© | Afficher l'Ã©tat
        """
        status = self.get_status()
        
        print("\n" + "=" * 60)
        print("ğŸ›¡ï¸ Ø­Ø§Ù„Ø© Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„ÙÙˆØ±ÙŠ | Ã‰tat du DÃ©tecteur")
        print("=" * 60)
        print(f"   ÙŠØ¹Ù…Ù„ | Running: {'âœ…' if status['running'] else 'âŒ'}")
        print(f"   Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | ModÃ¨le: {status['model_name']}")
        print(f"   Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­Ù…Ù‘Ù„ | ModÃ¨le chargÃ©: {'âœ…' if status['model_loaded'] else 'âŒ'}")
        print(f"   Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ Ù…Ø­Ù…Ù‘Ù„ | Scaler chargÃ©: {'âœ…' if status['scaler_loaded'] else 'âŒ'}")
        print(f"   Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙÙŠ Ø§Ù„Ù…Ø®Ø²Ù† | Ã‰vÃ©nements buffer: {status['events_in_buffer']}")
        print(f"   Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙƒØ´ÙˆÙØ§Øª | Total dÃ©tections: {status['total_detections']}")
        print(f"   Ø­Ù…ÙŠØ¯Ø© | BÃ©nins: {status['benign_count']}")
        print(f"   Ù…Ø´Ø¨ÙˆÙ‡Ø© | Malveillants: {status['malicious_count']}")
        print(f"   Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØ£Ø®ÙŠØ± | Latence moyenne: {status['avg_latency_ms']:.2f}ms")
        print(f"   Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© | RAM actuelle: {status['current_memory_mb']:.2f}MB")
        print("=" * 60)


class IntegratedDetector:
    """
    Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ | DÃ©tecteur IntÃ©grÃ©
    ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¬Ø§Ù…Ø¹ ÙˆØ§Ù„ÙƒØ§Ø´Ù ÙÙŠ ÙˆØ­Ø¯Ø© ÙˆØ§Ø­Ø¯Ø©
    Combine le collecteur et le dÃ©tecteur
    """
    
    def __init__(
        self,
        model_path: Optional[str] = None,
        scaler_path: Optional[str] = None,
        model_name: str = 'isolation_forest',
        config_path: Optional[str] = None
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ | Initialisation du dÃ©tecteur intÃ©grÃ©
        """
        # Ø§Ù„ÙƒØ§Ø´Ù | DÃ©tecteur
        self.detector = RealtimeDetector(
            model_path=model_path,
            scaler_path=scaler_path,
            model_name=model_name,
            config_path=config_path
        )
        
        # Ø§Ù„Ø¬Ø§Ù…Ø¹ | Collecteur
        if BehaviorCollector:
            self.collector = BehaviorCollector(config_path=config_path)
        else:
            self.collector = None
            logger.warning("Ø§Ù„Ø¬Ø§Ù…Ø¹ ØºÙŠØ± Ù…ØªÙˆÙØ± | Collecteur non disponible")
        
        self._running = False
        
        logger.info("ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ | DÃ©tecteur intÃ©grÃ© initialisÃ©")
    
    def start(self, detection_interval: float = 1.0):
        """
        Ø¨Ø¯Ø¡ Ø§Ù„ÙƒØ´Ù Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ | DÃ©marrer la dÃ©tection intÃ©grÃ©e
        """
        self._running = True
        
        # Ø¨Ø¯Ø¡ Ø§Ù„Ø¬Ø§Ù…Ø¹ | DÃ©marrer le collecteur
        if self.collector:
            self.collector.start()
        
        # Ø¨Ø¯Ø¡ Ø§Ù„ÙƒØ§Ø´Ù | DÃ©marrer le dÃ©tecteur
        self.detector.start(interval=detection_interval)
        
        logger.info("âœ… ØªÙ… Ø¨Ø¯Ø¡ Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ | DÃ©tecteur intÃ©grÃ© dÃ©marrÃ©")
    
    def stop(self):
        """
        Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ´Ù | ArrÃªter la dÃ©tection
        """
        self._running = False
        
        if self.collector:
            self.collector.stop()
        
        self.detector.stop()
        
        logger.info("âœ… ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ | DÃ©tecteur intÃ©grÃ© arrÃªtÃ©")
    
    def get_status(self) -> Dict:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© | Obtenir l'Ã©tat complet
        """
        status = {
            'running': self._running,
            'detector': self.detector.get_status(),
            'collector': self.collector.get_stats() if self.collector else {}
        }
        return status


def main():
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© | Fonction principale
    """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„ÙÙˆØ±ÙŠ | DÃ©tecteur en Temps RÃ©el"
    )
    parser.add_argument(
        '--model',
        type=str,
        default=None,
        help='Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Chemin du modÃ¨le'
    )
    parser.add_argument(
        '--scaler',
        type=str,
        default=None,
        help='Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ | Chemin du scaler'
    )
    parser.add_argument(
        '--model-name',
        type=str,
        default='isolation_forest',
        choices=['isolation_forest', 'one_class_svm', 'lof', 'random_forest', 'xgboost'],
        help='Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | Nom du modÃ¨le'
    )
    parser.add_argument(
        '--duration',
        type=int,
        default=60,
        help='Ù…Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ | DurÃ©e en secondes'
    )
    parser.add_argument(
        '--interval',
        type=float,
        default=1.0,
        help='ÙØªØ±Ø© Ø§Ù„ÙƒØ´Ù Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ | Intervalle de dÃ©tection'
    )
    
    args = parser.parse_args()
    
    # Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡ | Callback d'alerte
    def on_alert(result: DetectionResult):
        level_icons = {'normal': 'ğŸŸ¢', 'warning': 'ğŸŸ¡', 'danger': 'ğŸ”´'}
        icon = level_icons.get(result.alert_level, 'â“')
        print(f"\n{icon} ØªÙ†Ø¨ÙŠÙ‡ | Alerte: {result.prediction.upper()}")
        print(f"   Ø§Ù„Ø«Ù‚Ø© | Confiance: {result.confidence:.2%}")
        print(f"   Ø§Ù„ØªØ£Ø®ÙŠØ± | Latence: {result.latency_ms:.1f}ms")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒØ§Ø´Ù | CrÃ©er le dÃ©tecteur
    detector = RealtimeDetector(
        model_path=args.model,
        scaler_path=args.scaler,
        model_name=args.model_name
    )
    detector.set_alert_callback(on_alert)
    
    try:
        print("\n" + "=" * 60)
        print("ğŸ›¡ï¸ Ø§Ù„ÙƒØ§Ø´Ù Ø§Ù„ÙÙˆØ±ÙŠ | DÃ©tecteur en Temps RÃ©el")
        print("=" * 60)
        
        detector.start(interval=args.interval)
        
        print(f"\nâ³ ØªØ´ØºÙŠÙ„ Ù„Ù…Ø¯Ø© {args.duration} Ø«Ø§Ù†ÙŠØ© | Running for {args.duration}s...")
        print("Ø§Ø¶ØºØ· Ctrl+C Ù„Ù„Ø¥ÙŠÙ‚Ø§Ù | Press Ctrl+C to stop\n")
        
        for i in range(args.duration):
            time.sleep(1)
            if (i + 1) % 10 == 0:
                detector.print_status()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ØªÙˆÙ‚Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… | ArrÃªt par l'utilisateur")
    
    finally:
        detector.stop()
        detector.print_status()


if __name__ == "__main__":
    main()
