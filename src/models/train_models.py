"""
ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | EntraÃ®nement des ModÃ¨les | Model Training
ØªØ¯Ø±ÙŠØ¨ ÙˆÙ…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
EntraÃ®ner et comparer diffÃ©rents modÃ¨les ML
"""

import os
import json
import time
import joblib
import argparse
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any
from pathlib import Path
from datetime import datetime
import logging
import warnings

# ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª | Ignorer les avertissements
warnings.filterwarnings('ignore')

# Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ | ModÃ¨les ML
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.svm import OneClassSVM
from sklearn.neighbors import LocalOutlierFactor
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score
)

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False
    logging.warning("XGBoost ØºÙŠØ± Ù…ØªÙˆÙØ± | XGBoost non disponible")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ | Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelTrainer:
    """
    Ù…Ø¯Ø±Ø¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | EntraÃ®neur de ModÃ¨les
    ÙŠØ¯Ø±Ø¨ ÙˆÙŠÙ‚Ø§Ø±Ù† Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    EntraÃ®ne et compare diffÃ©rents modÃ¨les ML
    """
    
    def __init__(
        self,
        models_dir: Optional[str] = None,
        config: Optional[Dict] = None
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø¯Ø±Ø¨ | Initialisation de l'entraÃ®neur
        
        Args:
            models_dir: Ù…Ø¬Ù„Ø¯ Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | RÃ©pertoire de sauvegarde
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | Configuration des modÃ¨les
        """
        self.models_dir = Path(models_dir or './data/models')
        self.models_dir.mkdir(parents=True, exist_ok=True)
        
        self.config = config or self._get_default_config()
        self.scaler = StandardScaler()
        self.trained_models: Dict[str, Any] = {}
        self.results: Dict[str, Dict] = {}
        
        logger.info(f"ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù…Ø¯Ø±Ø¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | EntraÃ®neur initialisÃ©: {self.models_dir}")
    
    def _get_default_config(self) -> Dict:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        Obtenir la configuration par dÃ©faut
        """
        return {
            'isolation_forest': {
                'n_estimators': 100,
                'contamination': 0.1,
                'random_state': 42
            },
            'one_class_svm': {
                'kernel': 'rbf',
                'nu': 0.1,
                'gamma': 'auto'
            },
            'lof': {
                'n_neighbors': 20,
                'contamination': 0.1
            },
            'random_forest': {
                'n_estimators': 100,
                'max_depth': 10,
                'random_state': 42
            },
            'xgboost': {
                'n_estimators': 100,
                'max_depth': 6,
                'learning_rate': 0.1,
                'random_state': 42
            }
        }
    
    def load_data(
        self,
        data_path: str,
        feature_cols: Optional[List[str]] = None,
        target_col: str = 'label_numeric'
    ) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """
        ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Charger les donnÃ©es
        
        Args:
            data_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Chemin du fichier
            feature_cols: Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª | Colonnes des features
            target_col: Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù‡Ø¯Ù | Colonne cible
            
        Returns:
            X, y, feature_names
        """
        logger.info(f"ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† | Chargement depuis: {data_path}")
        
        df = pd.read_csv(data_path)
        
        # ØªØ­Ø¯ÙŠØ¯ Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª | DÃ©terminer les colonnes features
        if feature_cols is None:
            exclude_cols = ['label', 'label_numeric', 'window_start', 'window_end', 'event_count']
            feature_cols = [c for c in df.columns if c not in exclude_cols]
        
        X = df[feature_cols].values
        y = df[target_col].values if target_col in df.columns else None
        
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(X)} Ø¹ÙŠÙ†Ø© | {len(X)} Ã©chantillons chargÃ©s")
        logger.info(f"Ø§Ù„Ù…ÙŠØ²Ø§Øª | Features: {len(feature_cols)}")
        
        return X, y, feature_cols
    
    def prepare_data(
        self,
        X: np.ndarray,
        y: np.ndarray,
        test_size: float = 0.2,
        scale: bool = True
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """
        ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨ | PrÃ©parer les donnÃ©es pour l'entraÃ®nement
        """
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Diviser les donnÃ©es
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Normaliser les donnÃ©es
        if scale:
            X_train = self.scaler.fit_transform(X_train)
            X_test = self.scaler.transform(X_test)
        
        logger.info(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ | Training: {len(X_train)}")
        logger.info(f"Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± | Test: {len(X_test)}")
        
        return X_train, X_test, y_train, y_test
    
    # ==================== ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ====================
    # ==================== EntraÃ®nement des ModÃ¨les ====================
    
    def train_isolation_forest(
        self,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_test: np.ndarray
    ) -> Dict:
        """
        ØªØ¯Ø±ÙŠØ¨ Isolation Forest | EntraÃ®ner Isolation Forest
        """
        logger.info("ğŸŒ² ØªØ¯Ø±ÙŠØ¨ Isolation Forest...")
        
        config = self.config['isolation_forest']
        model = IsolationForest(**config)
        
        start_time = time.time()
        model.fit(X_train)
        train_time = time.time() - start_time
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ | PrÃ©diction
        # Isolation Forest: -1 = anomaly, 1 = normal
        # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ 0/1 | Convertir en 0/1
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        # ØªØ­ÙˆÙŠÙ„: -1 -> 1 (malicious), 1 -> 0 (benign)
        y_pred_test_binary = np.where(y_pred_test == -1, 1, 0)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ | Calculer les mÃ©triques
        metrics = self._calculate_metrics(y_test, y_pred_test_binary, model_type='unsupervised')
        metrics['train_time'] = train_time
        
        self.trained_models['isolation_forest'] = model
        self.results['isolation_forest'] = metrics
        
        return metrics
    
    def train_one_class_svm(
        self,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_test: np.ndarray
    ) -> Dict:
        """
        ØªØ¯Ø±ÙŠØ¨ One-Class SVM | EntraÃ®ner One-Class SVM
        """
        logger.info("ğŸ”® ØªØ¯Ø±ÙŠØ¨ One-Class SVM...")
        
        config = self.config['one_class_svm']
        model = OneClassSVM(**config)
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø§Ø¯ÙŠØ© ÙÙ‚Ø· | EntraÃ®ner sur les donnÃ©es normales
        X_train_normal = X_train[np.random.choice(len(X_train), min(1000, len(X_train)), replace=False)]
        
        start_time = time.time()
        model.fit(X_train_normal)
        train_time = time.time() - start_time
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ | PrÃ©diction
        y_pred_test = model.predict(X_test)
        y_pred_test_binary = np.where(y_pred_test == -1, 1, 0)
        
        metrics = self._calculate_metrics(y_test, y_pred_test_binary, model_type='unsupervised')
        metrics['train_time'] = train_time
        
        self.trained_models['one_class_svm'] = model
        self.results['one_class_svm'] = metrics
        
        return metrics
    
    def train_lof(
        self,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_test: np.ndarray
    ) -> Dict:
        """
        ØªØ¯Ø±ÙŠØ¨ Local Outlier Factor | EntraÃ®ner LOF
        """
        logger.info("ğŸ” ØªØ¯Ø±ÙŠØ¨ Local Outlier Factor...")
        
        config = self.config['lof']
        # LOF novelty=True Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
        model = LocalOutlierFactor(novelty=True, **config)
        
        X_train_sample = X_train[np.random.choice(len(X_train), min(2000, len(X_train)), replace=False)]
        
        start_time = time.time()
        model.fit(X_train_sample)
        train_time = time.time() - start_time
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ | PrÃ©diction
        y_pred_test = model.predict(X_test)
        y_pred_test_binary = np.where(y_pred_test == -1, 1, 0)
        
        metrics = self._calculate_metrics(y_test, y_pred_test_binary, model_type='unsupervised')
        metrics['train_time'] = train_time
        
        self.trained_models['lof'] = model
        self.results['lof'] = metrics
        
        return metrics
    
    def train_random_forest(
        self,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_train: np.ndarray,
        y_test: np.ndarray
    ) -> Dict:
        """
        ØªØ¯Ø±ÙŠØ¨ Random Forest | EntraÃ®ner Random Forest
        """
        logger.info("ğŸŒ³ ØªØ¯Ø±ÙŠØ¨ Random Forest...")
        
        config = self.config['random_forest']
        model = RandomForestClassifier(**config)
        
        start_time = time.time()
        model.fit(X_train, y_train)
        train_time = time.time() - start_time
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ | PrÃ©diction
        y_pred_test = model.predict(X_test)
        y_prob_test = model.predict_proba(X_test)[:, 1]
        
        metrics = self._calculate_metrics(y_test, y_pred_test, y_prob=y_prob_test, model_type='supervised')
        metrics['train_time'] = train_time
        metrics['feature_importance'] = dict(zip(
            range(X_train.shape[1]),
            model.feature_importances_
        ))
        
        self.trained_models['random_forest'] = model
        self.results['random_forest'] = metrics
        
        return metrics
    
    def train_xgboost(
        self,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_train: np.ndarray,
        y_test: np.ndarray
    ) -> Dict:
        """
        ØªØ¯Ø±ÙŠØ¨ XGBoost | EntraÃ®ner XGBoost
        """
        if not XGBOOST_AVAILABLE:
            logger.warning("XGBoost ØºÙŠØ± Ù…ØªÙˆÙØ± | XGBoost non disponible")
            return {}
        
        logger.info("ğŸš€ ØªØ¯Ø±ÙŠØ¨ XGBoost...")
        
        config = self.config['xgboost']
        model = xgb.XGBClassifier(**config, use_label_encoder=False, eval_metric='logloss')
        
        start_time = time.time()
        model.fit(X_train, y_train)
        train_time = time.time() - start_time
        
        # Ø§Ù„ØªÙ†Ø¨Ø¤ | PrÃ©diction
        y_pred_test = model.predict(X_test)
        y_prob_test = model.predict_proba(X_test)[:, 1]
        
        metrics = self._calculate_metrics(y_test, y_pred_test, y_prob=y_prob_test, model_type='supervised')
        metrics['train_time'] = train_time
        metrics['feature_importance'] = dict(zip(
            range(X_train.shape[1]),
            model.feature_importances_
        ))
        
        self.trained_models['xgboost'] = model
        self.results['xgboost'] = metrics
        
        return metrics
    
    def _calculate_metrics(
        self,
        y_true: np.ndarray,
        y_pred: np.ndarray,
        y_prob: Optional[np.ndarray] = None,
        model_type: str = 'supervised'
    ) -> Dict:
        """
        Ø­Ø³Ø§Ø¨ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡ | Calculer les mÃ©triques de performance
        """
        metrics = {
            'accuracy': float(accuracy_score(y_true, y_pred)),
            'precision': float(precision_score(y_true, y_pred, zero_division=0)),
            'recall': float(recall_score(y_true, y_pred, zero_division=0)),
            'f1': float(f1_score(y_true, y_pred, zero_division=0)),
            'confusion_matrix': confusion_matrix(y_true, y_pred).tolist(),
            'model_type': model_type
        }
        
        # Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª Ø§Ù„ÙƒØ§Ø°Ø¨Ø© | Taux de faux positifs
        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
        metrics['false_positive_rate'] = float(fp / (fp + tn)) if (fp + tn) > 0 else 0
        metrics['false_negative_rate'] = float(fn / (fn + tp)) if (fn + tp) > 0 else 0
        
        # AUC Ø¥Ø°Ø§ ØªÙˆÙØ±Øª Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª | AUC si probabilitÃ©s disponibles
        if y_prob is not None:
            try:
                metrics['auc'] = float(roc_auc_score(y_true, y_prob))
            except:
                metrics['auc'] = 0.0
        
        return metrics
    
    def train_all_models(
        self,
        X_train: np.ndarray,
        X_test: np.ndarray,
        y_train: np.ndarray,
        y_test: np.ndarray
    ) -> Dict[str, Dict]:
        """
        ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | EntraÃ®ner tous les modÃ¨les
        """
        logger.info("=" * 60)
        logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | EntraÃ®nement de tous les modÃ¨les")
        logger.info("=" * 60)
        
        # Ù†Ù…Ø§Ø°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬Ù‡Ø© (unsupervised) | ModÃ¨les non supervisÃ©s
        self.train_isolation_forest(X_train, X_test, y_test)
        self.train_one_class_svm(X_train, X_test, y_test)
        self.train_lof(X_train, X_test, y_test)
        
        # Ù†Ù…Ø§Ø°Ø¬ Ù…ÙˆØ¬Ù‡Ø© (supervised) | ModÃ¨les supervisÃ©s
        self.train_random_forest(X_train, X_test, y_train, y_test)
        self.train_xgboost(X_train, X_test, y_train, y_test)
        
        return self.results
    
    def save_models(self, suffix: str = ""):
        """
        Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | Sauvegarder tous les modÃ¨les
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for name, model in self.trained_models.items():
            if model is not None:
                filename = f"{name}{suffix}_{timestamp}.joblib"
                filepath = self.models_dir / filename
                joblib.dump(model, filepath)
                logger.info(f"ØªÙ… Ø­ÙØ¸ | SauvegardÃ©: {filename}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ | Sauvegarder le scaler
        scaler_path = self.models_dir / f"scaler{suffix}_{timestamp}.joblib"
        joblib.dump(self.scaler, scaler_path)
        logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ | Scaler sauvegardÃ©")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ | Sauvegarder les rÃ©sultats
        results_path = self.models_dir / f"results{suffix}_{timestamp}.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ | RÃ©sultats sauvegardÃ©s")
    
    def load_model(self, model_name: str, model_path: str):
        """
        ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙÙˆØ¸ | Charger un modÃ¨le sauvegardÃ©
        """
        model = joblib.load(model_path)
        self.trained_models[model_name] = model
        logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ | ModÃ¨le chargÃ©: {model_name}")
        return model
    
    def compare_models(self) -> pd.DataFrame:
        """
        Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | Comparer les performances des modÃ¨les
        """
        comparison_data = []
        
        for name, metrics in self.results.items():
            if metrics:
                comparison_data.append({
                    'Model': name,
                    'Accuracy': metrics.get('accuracy', 0),
                    'Precision': metrics.get('precision', 0),
                    'Recall': metrics.get('recall', 0),
                    'F1': metrics.get('f1', 0),
                    'AUC': metrics.get('auc', 0),
                    'FPR': metrics.get('false_positive_rate', 0),
                    'Train Time (s)': metrics.get('train_time', 0)
                })
        
        df = pd.DataFrame(comparison_data)
        df = df.sort_values('F1', ascending=False)
        
        return df
    
    def print_comparison(self):
        """
        Ø·Ø¨Ø§Ø¹Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | Afficher la comparaison des modÃ¨les
        """
        df = self.compare_models()
        
        print("\n" + "=" * 90)
        print("ğŸ“Š Ù…Ù‚Ø§Ø±Ù†Ø© Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | Comparaison des Performances")
        print("=" * 90)
        print(df.to_string(index=False))
        print("=" * 90)
        
        # Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ | Meilleur modÃ¨le
        if len(df) > 0:
            best_model = df.iloc[0]['Model']
            best_f1 = df.iloc[0]['F1']
            print(f"\nğŸ† Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ | Meilleur modÃ¨le: {best_model} (F1: {best_f1:.4f})")


def main():
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© | Fonction principale
    """
    parser = argparse.ArgumentParser(
        description="ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | EntraÃ®nement des ModÃ¨les"
    )
    parser.add_argument(
        '--data', '-d',
        type=str,
        required=True,
        help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Chemin du fichier de donnÃ©es'
    )
    parser.add_argument(
        '--output', '-o',
        type=str,
        default='./data/models',
        help='Ù…Ø¬Ù„Ø¯ Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | RÃ©pertoire de sauvegarde'
    )
    parser.add_argument(
        '--test-size',
        type=float,
        default=0.2,
        help='Ù†Ø³Ø¨Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± | Ratio de test'
    )
    
    args = parser.parse_args()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù | VÃ©rifier l'existence du fichier
    if not os.path.exists(args.data):
        logger.error(f"Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ | Fichier non trouvÃ©: {args.data}")
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø¨ | CrÃ©er l'entraÃ®neur
    trainer = ModelTrainer(models_dir=args.output)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | Charger les donnÃ©es
    X, y, feature_names = trainer.load_data(args.data)
    
    if y is None:
        logger.error("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù‡Ø¯Ù | Pas de colonne cible")
        return
    
    # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª | PrÃ©parer les donnÃ©es
    X_train, X_test, y_train, y_test = trainer.prepare_data(X, y, test_size=args.test_size)
    
    # ØªØ¯Ø±ÙŠØ¨ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | EntraÃ®ner tous les modÃ¨les
    trainer.train_all_models(X_train, X_test, y_train, y_test)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© | Afficher la comparaison
    trainer.print_comparison()
    
    # Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ | Sauvegarder les modÃ¨les
    trainer.save_models()
    
    logger.info("âœ… ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ | TerminÃ©")


if __name__ == "__main__":
    main()
